# FYRMTECH Robots.txt
# Define crawling rules for search engines

# Allow all bots to crawl the website
User-agent: *
Allow: /

# Disallow directories
Disallow: /scripts/
Disallow: /.git/
Disallow: /.github/
Disallow: /.venv/
Disallow: /node_modules/

# Googlebot - Note: Googlebot ignores Crawl-delay
# Use Google Search Console to control crawl rate instead
User-agent: Googlebot
Allow: /

# Bingbot
User-agent: Bingbot
Allow: /
Crawl-delay: 1

# Yahoo Slurp
User-agent: Slurp
Allow: /
Crawl-delay: 1

# Disallow bad bots
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: DotBot
Disallow: /

# Sitemaps
Sitemap: https://www.fyrmtech.com/sitemap.xml
Sitemap: https://www.fyrmtech.com/sitemap-images.xml
